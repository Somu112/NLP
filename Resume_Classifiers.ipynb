{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume Classifiers ",
      "provenance": [],
      "authorship_tag": "ABX9TyNnkpu6YEdngjNZKAtHg2mb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Somu112/NLP/blob/main/Resume_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRKlfvtnAoED"
      },
      "source": [
        "**Resume Classification**\n",
        "\n",
        "\n",
        "In this case we are using a bunch of Resumes in .DOCX format which is the latest format in which we save MS Word files.\n",
        "\n",
        "In case we have resumes in PDF Format we would need to use the appropriate library to read the PDF Files as Text.\n",
        "\n",
        "We would separately be using a skills document to further understand the skills in the available resumes and finally perform the classification of which particular resumes are fit for our given role."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ3m-Tdu2U4t",
        "outputId": "a4981d74-0fcf-49b6-c67d-863645b323bd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  4 10:34:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWSD1FMJ6FX2",
        "outputId": "49fdfae6-cd4a-46b8-9285-4abfec2c2f9d"
      },
      "source": [
        "!pip install python-docx"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from python-docx) (4.2.6)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184508 sha256=42254f298a024a12b8463cf7523aa914650aded70c72af93b6459f62a12660bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-0.8.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S3eyy8f3c5M"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import spacy as sy\n",
        "import docx\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from spacy.lang.en import English\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import json\n",
        "import random\n",
        "from spacy.matcher import Matcher\n",
        "import re\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from io import StringIO\n",
        "from collections import Counter\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvK3PjctAfPr"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3g9YAdw5Q4x",
        "outputId": "37c25c59-0f4c-4e11-e3dd-a8f60becf0b9"
      },
      "source": [
        "# unzip the available set of resumes.\n",
        "# note: please upload the dataset which is shared already in LMS into Colab env. \n",
        "!unzip '/content/dataset.zip'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "  inflating: data/Abiral_Pandey_Fullstack_Java.docx  \n",
            "  inflating: data/Achyuth Resume_8.docx  \n",
            "  inflating: data/Adelina_Erimia_PMP1.docx  \n",
            "  inflating: data/Adhi Gopalam - SM.docx  \n",
            "  inflating: data/AjayKumar.docx     \n",
            "  inflating: data/Akhil.profile.docx  \n",
            "  inflating: data/Akhil_Sr BSA.docx  \n",
            "  inflating: data/Alekhya Resume.docx  \n",
            "  inflating: data/Amar Sr BSA.docx   \n",
            "  inflating: data/Ami Jape.docx      \n",
            "  inflating: data/Amrinder Business Analyst.docx  \n",
            "  inflating: data/Amulya Komatineni.docx  \n",
            "  inflating: data/Anil Krishna Mogalaturthi.docx  \n",
            "  inflating: data/AnilAgarwal.docx   \n",
            "  inflating: data/Anudeep N_Sr Java Developer.docx  \n",
            "  inflating: data/Ashok Jayakumar - PM.docx  \n",
            "  inflating: data/Ashwini J2EE Developer.docx  \n",
            "  inflating: data/Atul_Mathur_Resume.docx  \n",
            "  inflating: data/Avathika BA-Healthcare_.docx  \n",
            "  inflating: data/avinash G.docx     \n",
            "  inflating: data/B Shaker-Sr BSA-Scrum Master .docx  \n",
            "  inflating: data/B Suresh Kumar_Project Manager_1.docx  \n",
            "  inflating: data/BA - Abhishek.docx  \n",
            "  inflating: data/BA - Navneet.docx  \n",
            "  inflating: data/BA Kiran.docx      \n",
            "  inflating: data/BA with INV.docx   \n",
            "  inflating: data/Balaji Gopalakrishnan Project Manager.docx  \n",
            "  inflating: data/Balakrishna Sudabathula.docx  \n",
            "  inflating: data/Bapuji Hadoop developer.docx  \n",
            "  inflating: data/Bharat Arora_CV_PMP _ ERP1.docx  \n",
            "  inflating: data/Bharatha BA Resume.docx  \n",
            "  inflating: data/Brahma-Resume (BA).docx  \n",
            "  inflating: data/Business Analyst_GHyma.docx  \n",
            "  inflating: data/Chandler_BA.docx   \n",
            "  inflating: data/chenna kesava.docx  \n",
            "  inflating: data/CHETAN_Sr Java Developer.docx  \n",
            "  inflating: data/Dantu Padmasri - Project Manager.docx  \n",
            "  inflating: data/Dave.docx          \n",
            "  inflating: data/Deepika Chintalapati.docx  \n",
            "  inflating: data/Deepika DC.docx    \n",
            "  inflating: data/Derik.docx         \n",
            "  inflating: data/Dhanalaxmi -BA.docx  \n",
            "  inflating: data/Drakshajavauidev.docx  \n",
            "  inflating: data/employer_mounika details.docx  \n",
            "  inflating: data/Francis Gomes Resume.docx  \n",
            "  inflating: data/Gautami Bulusu Mobile Testing 3.docx  \n",
            "  inflating: data/Gokul Selvam S PM.docx  \n",
            "  inflating: data/Gopi.docx          \n",
            "  inflating: data/Gururaja Murthy PMCPCSM.docx  \n",
            "  inflating: data/Haarika_BA.docx    \n",
            "  inflating: data/HARI_Sr.Java Developer.docx  \n",
            "  inflating: data/Harika_java.docx   \n",
            "  inflating: data/Harish K.docx      \n",
            "  inflating: data/harish S.docx      \n",
            "  inflating: data/Harshitha Challa.docx  \n",
            "  inflating: data/indrakaran soma.docx  \n",
            "  inflating: data/jagadeesh k.docx   \n",
            "  inflating: data/Jagan S Iyer PM.docx  \n",
            "  inflating: data/Jaya prakash.docx  \n",
            "  inflating: data/Jayadattaperi N.docx  \n",
            "  inflating: data/jeck P.docx        \n",
            "  inflating: data/Jennifer  M. Conte.docx  \n",
            "  inflating: data/Jimi_Desai_PM.docx  \n",
            "  inflating: data/kalyan das.docx    \n",
            "  inflating: data/Kashyap K. Vora resume.docx  \n",
            "  inflating: data/KIRAN KUMAR.docx   \n",
            "  inflating: data/komal patel.docx   \n",
            "  inflating: data/Komala BSA Resume.docx  \n",
            "  inflating: data/Krishna Kuruvella.docx  \n",
            "  inflating: data/Krishna Sr. BSA Resume.docx  \n",
            "  inflating: data/Krishna_BSA.docx   \n",
            "  inflating: data/Krishna_SrJava.docx  \n",
            "  inflating: data/Krishnapriya_BA.docx  \n",
            "  inflating: data/Kumar Raj.docx     \n",
            "  inflating: data/Kuppurajbabu_BA.docx  \n",
            "  inflating: data/KY BA PM UPDATED RESUME .docx  \n",
            "  inflating: data/Madhu_BA_AW.DOCX   \n",
            "  inflating: data/Madhuri Pawar.docx  \n",
            "  inflating: data/madhuri R.docx     \n",
            "  inflating: data/madhuri_java.docx  \n",
            "  inflating: data/mahesh_Java.docx   \n",
            "  inflating: data/Mahesh_Kamath_PM (1).docx  \n",
            "  inflating: data/Mani_Hadoop.docx   \n",
            "  inflating: data/Manikanta P.docx   \n",
            "  inflating: data/manish_singh_resume.docx  \n",
            "  inflating: data/Manohar B.docx     \n",
            "  inflating: data/Manohar Reddy.docx  \n",
            "  inflating: data/manohar.B.docx     \n",
            "  inflating: data/Mehul.docx         \n",
            "  inflating: data/Mitali Barman_Resume.docx  \n",
            "  inflating: data/Mohamad Jamil.docx  \n",
            "  inflating: data/Mohammad Resume.docx  \n",
            "  inflating: data/mohid_rj.docx      \n",
            "  inflating: data/mounika BA resume 7.docx  \n",
            "  inflating: data/Mounika health care resume.docx  \n",
            "  inflating: data/Mounika_P.docx     \n",
            "  inflating: data/MounikaReddy.docx  \n",
            "  inflating: data/Murali_Project Manager QA.DOCX  \n",
            "  inflating: data/Nandini_Resume.docx  \n",
            "  inflating: data/Naren Sr.BA .docx  \n",
            "  inflating: data/Naren Sr.BA.docx   \n",
            "  inflating: data/Naresh V.docx      \n",
            "  inflating: data/Naveen Arora.docx  \n",
            "  inflating: data/Naveen Kumar Bandela.docx  \n",
            "  inflating: data/Naveen.S_Resume.docx  \n",
            "  inflating: data/Navneeth Resume.docx  \n",
            "  inflating: data/Neha Mugghala.docx  \n",
            "  inflating: data/Nikhil.docx        \n",
            "  inflating: data/Nikith Reddy.docx  \n",
            "  inflating: data/Nikki_Nimmagadd.docx  \n",
            "  inflating: data/Nilesh-resume_1_phplead.docx  \n",
            "  inflating: data/Niteesh Java Developer.docx  \n",
            "  inflating: data/nithin katapally.docx  \n",
            "  inflating: data/nithin Reddy.docx  \n",
            "  inflating: data/Othman - Project Manager.docx  \n",
            "  inflating: data/Pankaj BSA.docx    \n",
            "  inflating: data/ParthMPatel_BA.docx  \n",
            "  inflating: data/Pavan Kumar Full Stack Java Developer.docx  \n",
            "  inflating: data/Pavan Sr Business Analyst resume.docx  \n",
            "  inflating: data/Pierre John.docx   \n",
            "  inflating: data/PM RESUME.docx     \n",
            "  inflating: data/Pranay P.docx      \n",
            "  inflating: data/Prashant Chawda_resume.docx  \n",
            "  inflating: data/Praveen B.docx     \n",
            "  inflating: data/Praveen T.docx     \n",
            "  inflating: data/Priya B.docx       \n",
            "  inflating: data/Priya_Sharma.docx  \n",
            "  inflating: data/Priyanka Sr BSA Resume.docx  \n",
            "  inflating: data/Raja Santhosam_PM Scrum Master.DOCX  \n",
            "  inflating: data/Rajendra-PMP-CSM.docx  \n",
            "  inflating: data/Rajesh_k.docx      \n",
            "  inflating: data/Raju Goduguchinta_Technical Program Manager.docx  \n",
            "  inflating: data/ram krishna.docx   \n",
            "  inflating: data/ram nandyala.docx  \n",
            "  inflating: data/Ramachandra EDA.docx  \n",
            "  inflating: data/Ramteja Motupalli.docx  \n",
            "  inflating: data/RAMYA BUSINESS ANALYST RESUME.docx  \n",
            "  inflating: data/Randy Adams.docx   \n",
            "  inflating: data/Ranjan_Project Manager-Scrum Master.docx  \n",
            "  inflating: data/Rao_Java.docx      \n",
            "  inflating: data/Rashmitha R.docx   \n",
            "  inflating: data/Ravi Pattar- Sr. Agile Program manager.docx  \n",
            "  inflating: data/Ravi Reddy.docx    \n",
            "  inflating: data/RaviBurra_Certified PM_DevOps.docx  \n",
            "  inflating: data/ravikiran JALASUTRAPU.docx  \n",
            "  inflating: data/RaviRaju_Resume.docx  \n",
            "  inflating: data/Reddemma_Lankipalle.docx  \n",
            "  inflating: data/Resume - Kishore Kotapati - 218E - BA.docx  \n",
            "  inflating: data/Resume - PM Agile-Scrum.docx  \n",
            "  inflating: data/Resume - Sr PM.docx  \n",
            "  inflating: data/Resume Vishal PM - MSIS, PMP-PMI.docx  \n",
            "  inflating: data/Resume_Spoorti Pandit_BSA.docx  \n",
            "  inflating: data/Resume2018March.docx  \n",
            "  inflating: data/Robinson.docx      \n",
            "  inflating: data/Rohanu Resume.docx  \n",
            "  inflating: data/ronith s.docx      \n",
            "  inflating: data/Sahas BA Resume.docx  \n",
            "  inflating: data/Sahithi K.docx     \n",
            "  inflating: data/sai k.docx         \n",
            "  inflating: data/Sai Krishna BA.docx  \n",
            "  inflating: data/Sai kumar.docx     \n",
            "  inflating: data/Sai Srinivas_Sr_Java_Developer.docx  \n",
            "  inflating: data/sairithvik alla.docx  \n",
            "  inflating: data/Saiteja G.docx     \n",
            "  inflating: data/Samir Naik-NJ - Feb 2018-V6.0.docx  \n",
            "  inflating: data/Samir Naik-NJ - Mar 2018-V3.0.docx  \n",
            "  inflating: data/sanjay kumar.docx  \n",
            "  inflating: data/Santosh Arugula BA.docx  \n",
            "  inflating: data/Sarath M.docx      \n",
            "  inflating: data/SaravanaKumar.docx  \n",
            "  inflating: data/Satish Reddy.docx  \n",
            "  inflating: data/Satish Uduta.docx  \n",
            "  inflating: data/SAURABH_PM.docx    \n",
            "  inflating: data/Shail_Tank-Business Analyst .docx  \n",
            "  inflating: data/Shaker Resume.docx  \n",
            "  inflating: data/Sharath Java.docx  \n",
            "  inflating: data/Shashank.docx      \n",
            "  inflating: data/Shelly Woods.docx  \n",
            "  inflating: data/Shiuli Mahmud.docx  \n",
            "  inflating: data/Shiva G-Java Resume.docx  \n",
            "  inflating: data/Siddhartha Gandroju.docx  \n",
            "  inflating: data/Smita Kamble_Resume.docx  \n",
            "  inflating: data/Sougandh_Java Fullstack Developer.docx  \n",
            "  inflating: data/Spoorthi Finance BSA Resume.docx  \n",
            "  inflating: data/Sr. Business Analyst.docx  \n",
            "  inflating: data/Sravani Battu.docx  \n",
            "  inflating: data/Sravani Singirikonda.docx  \n",
            "  inflating: data/Sri Gati.docx      \n",
            "  inflating: data/srinivas b.docx    \n",
            "  inflating: data/Srivatsan_Project_Manager.docx  \n",
            "  inflating: data/Sudhakar Reddy.docx  \n",
            "  inflating: data/Sumanth Manne Java Developer.docx  \n",
            "  inflating: data/Sundar_Java_8+ Years..docx  \n",
            "  inflating: data/SUNITHA Project Manager (1).docx  \n",
            "  inflating: data/Syed_Zia_Ashraf.docx  \n",
            "  inflating: data/Tanmay_Dam_Resume_BA.docx  \n",
            "  inflating: data/Tarun Resume.docx  \n",
            "  inflating: data/Tarun RESUME-BSAT.docx  \n",
            "  inflating: data/Tarun.docx         \n",
            "  inflating: data/Tarun_Developer.docx  \n",
            "  inflating: data/Tejaswi-resume.docx  \n",
            "  inflating: data/TeresaNeetipudi IT BA.DOCX  \n",
            "  inflating: data/Tushar Patel.docx  \n",
            "  inflating: data/Uday_Maripelly.docx  \n",
            "  inflating: data/Ujvala BA Feb 20.docx  \n",
            "  inflating: data/Utthan Silawal12.docx  \n",
            "  inflating: data/V Ashok A.docx     \n",
            "  inflating: data/Vamshi L.docx      \n",
            "  inflating: data/Vamshi Teja_Business Analyst.docx  \n",
            "  inflating: data/Varun Kumar.docx   \n",
            "  inflating: data/Varun.docx         \n",
            "  inflating: data/vema reddy.docx    \n",
            "  inflating: data/Venkat_BA.docx     \n",
            "  inflating: data/Venkata_Sr.PHP_Developer.docx  \n",
            "  inflating: data/venu b.docx        \n",
            "  inflating: data/Vijay Bhargav.docx  \n",
            "  inflating: data/VIJETHA G.docx     \n",
            "  inflating: data/vikas java.docx    \n",
            "  inflating: data/Vikash_BA_Ab.docx  \n",
            "  inflating: data/Vinay.D_Resume.docx  \n",
            "  inflating: data/Vishal S..docx     \n",
            "  inflating: data/Vishnu BA Resume.docx  \n",
            "  inflating: data/Vishnu J.docx      \n",
            "  inflating: data/Vishnu Java dev.docx  \n",
            "  inflating: data/Vivek Joshi_CV.docx  \n",
            "  inflating: data/Vivek.BSA.docx     \n",
            "  inflating: data/Yohan BSA.docx     \n",
            "  inflating: data/Yugesh_Resume.docx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRBalHrT6oIC"
      },
      "source": [
        "def getText(file):\n",
        "    doc = docx.Document(file) # reading each document file, resumes in this case\n",
        "    fullText=[] # empty corpus variable, where we can store the text \n",
        "    for paragraph in doc.paragraphs:\n",
        "        fullText.append(paragraph.text) # add each paragraph from the available text\n",
        "    return '\\n\\n'.join(fullText)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H8yyxwb686S"
      },
      "source": [
        "# creating the directory if that does not exist already\n",
        "if not os.path.exists('text_data'):\n",
        "    os.mkdir('text_data')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7-lqirz6tHf",
        "outputId": "216bd405-dac0-4d6e-a664-a13cc8d11e86"
      },
      "source": [
        "# Before proceeding please ensure that all the .docx files are in data folder\n",
        "data={'file':[],'text':[]} # dict. to store the file name and the text in that file. \n",
        "for file in tqdm(os.listdir('data')):\n",
        "        data['file'].append(file) # getting the file name \n",
        "        text=getText(os.path.join('data',file))\n",
        "        data['text'].append(text) # getting the text within the file \n",
        "        with open(os.path.join('text_data',str(file)+'.txt'),'w',encoding=\"utf-8\") as f:\n",
        "            f.writelines(text) # created .txt file for easier analysis of each resume file. \n",
        "        "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 228/228 [00:05<00:00, 41.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgSzBSw3AP7b"
      },
      "source": [
        "**Extracting Names and Resume**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPmilycW6xYF"
      },
      "source": [
        "# importing the data as a Pandas dataframe\n",
        "data=pd.DataFrame(data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sxrvwGct7FES",
        "outputId": "607155f4-9352-45bf-9ec1-d2d3f19dea9e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Francis Gomes Resume.docx</td>\n",
              "      <td>Professional summary  \\n\\n16 + years of experi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Uday_Maripelly.docx</td>\n",
              "      <td>\\n\\nUday Maripelly\\n\\nSENIOR QA AUTOMATION ENG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Varun.docx</td>\n",
              "      <td>Varun\\n\\nOBJECTIVE:  \\t\\n\\nSeeking a position ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Manohar Reddy.docx</td>\n",
              "      <td>Manohar\\n\\nSr. Java Developer\\n\\n\\n\\nEmail:   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pavan Kumar Full Stack Java Developer.docx</td>\n",
              "      <td>PAVAN KUMAR\\t\\t\\t               Pavank068...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         file                                               text\n",
              "0                   Francis Gomes Resume.docx  Professional summary  \\n\\n16 + years of experi...\n",
              "1                         Uday_Maripelly.docx  \\n\\nUday Maripelly\\n\\nSENIOR QA AUTOMATION ENG...\n",
              "2                                  Varun.docx  Varun\\n\\nOBJECTIVE:  \\t\\n\\nSeeking a position ...\n",
              "3                          Manohar Reddy.docx  Manohar\\n\\nSr. Java Developer\\n\\n\\n\\nEmail:   ...\n",
              "4  Pavan Kumar Full Stack Java Developer.docx       PAVAN KUMAR\\t\\t\\t               Pavank068..."
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbBCJ_NC7IyA"
      },
      "source": [
        "st_en = sy.load('en_core_web_sm')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-G--MFQ7SKd"
      },
      "source": [
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(st_en.vocab)\n",
        "\n",
        "# user defined function:\n",
        "# getting the proper names of the candidates.  \n",
        "def getName(resume_text,st_en):\n",
        "    nlp_text = st_en(resume_text)\n",
        "    \n",
        "    # First name and Last name are always Proper Nouns\n",
        "    ptrn = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    matcher.add('NAME', None, ptrn)\n",
        "    matches = matcher(nlp_text)\n",
        "    \n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cx6RSBC7WEI",
        "outputId": "44436542-2801-4653-9265-ef835dc31360"
      },
      "source": [
        "# for example, print the name of the 12th file in the list. \n",
        "print('Name:',getName(data.text.iloc[12],st_en))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Agile RUP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VLOKs_zADwl"
      },
      "source": [
        "**Extracting contact**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzYK0jX7Znh"
      },
      "source": [
        "# User defined function:\n",
        "# using Python regular expressions to find the contact numbers of each candidate \n",
        "def getContact(text):\n",
        "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)    \n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "        if len(number) > 10:\n",
        "            return '+' + number\n",
        "        else:\n",
        "            return number"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmnMcsxh7dQ7",
        "outputId": "ca9f35fb-4096-49b5-fdd2-382afc072b7b"
      },
      "source": [
        "print('Contact:',getContact(data.text.iloc[14]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contact: +19404370150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw6tBOUz_909"
      },
      "source": [
        "**Extracting Email**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZsQ8JAU7gDu"
      },
      "source": [
        "# similar to extracting phone numbers, we can also extract emails. \n",
        "def getEmail(email):\n",
        "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
        "    if email:\n",
        "        try:\n",
        "            return email[0].split()[0].strip(';')\n",
        "        except IndexError:\n",
        "            return None"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgBpGsU87jpE",
        "outputId": "88166598-76bf-4621-daed-31deef4db19f"
      },
      "source": [
        "# test print\n",
        "print('Email:',getEmail(data.text.iloc[102]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Email: usilawal123@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxJxprvl_tH2"
      },
      "source": [
        "**Extracting Education**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-anNTQNx7m9A"
      },
      "source": [
        "# Education Degrees\n",
        "EDUCATION = [\n",
        "            'BE','B.E.', 'B.E', 'BS', 'B.S', \n",
        "            'ME', 'M.E', 'M.E.', 'MS', 'M.S', \n",
        "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH', \n",
        "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
        "        ]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDB0k2lX7qmY"
      },
      "source": [
        "# user defined function to extract the Education qualifications as per the set list of values\n",
        "def getEducation(resume_text,st_en):\n",
        "    nlp_text = st_en(resume_text)\n",
        "\n",
        "    # Sentence Tokenizer\n",
        "    nlp_text = [sent.string.strip() for sent in nlp_text.sents]\n",
        "\n",
        "    edu = {}\n",
        "    # Extract education degree\n",
        "    for index, text in enumerate(nlp_text):\n",
        "        for tex in text.split():\n",
        "            # Replace all special symbols\n",
        "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
        "            if tex.upper() in EDUCATION and not st_en.vocab[tex].is_stop:\n",
        "                edu[tex] = text + nlp_text[index]\n",
        "\n",
        "    # Extract year\n",
        "    education = []\n",
        "    for key in edu.keys():\n",
        "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
        "        if year:\n",
        "            education.append((key, ''.join(year[0])))\n",
        "        else:\n",
        "            education.append(key)\n",
        "    return education"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKTRWKmD7uP0",
        "outputId": "19b7211b-ed50-4b35-e32e-29484127effd"
      },
      "source": [
        "print('Education:',getEducation(data.text.iloc[51],st_en),sep='\\n')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Education:\n",
            "['MS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWVyWaV4_fqZ"
      },
      "source": [
        "**Extracting Skills**\n",
        "\n",
        "To extract skills, we will need some extra help from a predefined set of skills. To serve that purpose we have a skill.csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA1Uc2mE7w9E"
      },
      "source": [
        "# creating this user defined function, using the skill.csv where we have already listed\n",
        "# all the common skills that we are looking for as part of the requirements/hiring\n",
        "def getSkills(resume_text,st_en):\n",
        "    nlp_text = st_en(resume_text)\n",
        "    noun_chunks = nlp_text.noun_chunks # taking only the NOUNS \n",
        "    # removing stop words and implementing word tokenization\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    data = pd.read_csv(\"skills.csv\") \n",
        "    skills = list(data.columns.values)\n",
        "    skillset = []\n",
        "    \n",
        "    # check for one-grams (example: python)\n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    # check for bi-grams and tri-grams (example: machine learning)\n",
        "    for token in noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    return [i.capitalize() for i in set([i.lower() for i in skillset])]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTGiKO-l71kD",
        "outputId": "93152846-61d5-4068-f852-8bd84160e2c5"
      },
      "source": [
        "print('Skills:',getSkills(data.text.iloc[140],st_en),sep='\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skills:\n",
            "['Software development life cycle', 'Underwriting', 'Open source', 'Transactions', 'Email', 'Ruby', 'Apis', 'Workflows', 'Ui', 'Mobile', 'Coding', 'Adobe', 'Jira', 'Unix', 'Mock', 'Reports', 'Pattern', 'Inventory', 'Banking', 'Debugging', 'Css', 'Js', 'Broadcast', 'Pl/sql', 'Windows', 'Workflow', 'Flex', 'Documentation', 'Mortgage', 'Technical skills', 'Communication', 'Database', 'Distribution', 'Oracle', 'Html', 'Design', 'Servers', 'Security', 'Vmware', 'Administration', 'Reporting', 'Rest', 'Usability', 'Presentation', 'Hospital', 'Logging', 'Xml', 'Sdlc', 'Operations', 'Nosql', 'Website', 'Soap', 'Pharmacy', 'Jsp', 'Billing', 'Shell', 'Automation', 'Health', 'Technical', 'Scheduling', 'Selenium', 'Requests', 'Mysql', 'System', 'Html5', 'Aws', 'Ibm', 'Java', 'Analysis', 'Access', 'Scrum', 'Agile', 'Docker', 'Php', 'Javascript', 'Queries', 'Json', 'Sql server', 'Architecture', 'Admissions', 'Writing', 'Web services', 'Linux', 'Programming', 'Threading', 'Test cases', 'Cloud', 'Testing', 'Process', 'Routing', 'Api', 'Prototype', 'Sql']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KidEOH7V77LW",
        "outputId": "055d7b1f-985f-4b7f-cab4-87a973600db0"
      },
      "source": [
        "print('Name:',getName(data.text.iloc[12],st_en))\n",
        "print('Skills:',getSkills(data.text.iloc[12],st_en),sep='\\n')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Agile RUP\n",
            "Skills:\n",
            "['Software development life cycle', 'Asp', 'Microsoft visio', 'Test plans', 'Plan', 'Word', 'Legal', 'Conversion', 'Presentations', 'Quality assurance', 'Ui', 'Adobe', 'Jad', 'Jira', 'Reports', 'Sharepoint', 'Mock', 'Excel', 'Documentation', 'Modeling', 'Proposal', 'Training', 'Project management', 'Communication', 'Market research', 'Database', 'C#', 'Oracle', 'Html', 'Design', 'Crm', 'Audit', 'Policies', 'Ms excel', 'Administration', 'Schedules', 'Presentation', 'Content', 'Ecommerce', 'Specifications', 'Xml', 'Sdlc', 'Visio', 'Operations', 'C', 'Budget', 'Warehouse', 'Website', 'Analytical', 'Vendors', 'Compliance', 'C++', 'International', 'Jsp', 'Project planning', 'Budgeting', 'Technical', 'Requests', 'Metrics', 'System', 'Reconciliation', 'Logistics', 'Ibm', 'Benchmark', 'Java', 'Hp alm', 'Analysis', 'Access', 'Scrum', 'Agile', 'Architecture', 'Research', 'Gap analysis', 'Ms project', 'Writing', 'Test cases', 'Testing', 'Process', 'Sql']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJYGIIHK8Ask"
      },
      "source": [
        "gsheet=\"https://docs.google.com/spreadsheets/d/1vZzA3Ccx5vM4d-CiCloCnbyMrU0Pdo134450Z5L6YrI/edit#gid=0\"\n",
        "url_1 = gsheet.replace('/edit#gid=', '/export?format=csv&gid=')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FV9jj_68FD-"
      },
      "source": [
        "ky_roles = pd.read_csv(url_1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "ZfAckxTm8ICK",
        "outputId": "e06527ee-0edc-4694-91aa-fe42ace62df1"
      },
      "source": [
        "ky_roles.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statistician</th>\n",
              "      <th>Machine Learning Engineer</th>\n",
              "      <th>Deep Learning Engineer</th>\n",
              "      <th>Python Developer</th>\n",
              "      <th>NLP Engineer</th>\n",
              "      <th>Data Engineering</th>\n",
              "      <th>JAVA developer</th>\n",
              "      <th>Cloud Engineer</th>\n",
              "      <th>Web Developer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>statistical models</td>\n",
              "      <td>Ruby</td>\n",
              "      <td>neural network</td>\n",
              "      <td>python</td>\n",
              "      <td>nlp</td>\n",
              "      <td>laws</td>\n",
              "      <td>Java</td>\n",
              "      <td>AWS</td>\n",
              "      <td>Javascript</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>statistical modeling</td>\n",
              "      <td>Python</td>\n",
              "      <td>keras</td>\n",
              "      <td>flask</td>\n",
              "      <td>natural language processing</td>\n",
              "      <td>ec2</td>\n",
              "      <td>J2ee</td>\n",
              "      <td>GCP</td>\n",
              "      <td>Typescript</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>probability</td>\n",
              "      <td>SAS</td>\n",
              "      <td>theano</td>\n",
              "      <td>django</td>\n",
              "      <td>topic modeling</td>\n",
              "      <td>amazon redshift</td>\n",
              "      <td>Object Oriented Programming</td>\n",
              "      <td>Amazon Web Services</td>\n",
              "      <td>HTML</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>normal distribution</td>\n",
              "      <td>SPSS</td>\n",
              "      <td>face detection</td>\n",
              "      <td>pandas</td>\n",
              "      <td>Ida</td>\n",
              "      <td>s3</td>\n",
              "      <td>OOPs</td>\n",
              "      <td>Google Cloud</td>\n",
              "      <td>HTML5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>poisson distribution</td>\n",
              "      <td>Weka</td>\n",
              "      <td>neural networks</td>\n",
              "      <td>numpy</td>\n",
              "      <td>named entity recognition</td>\n",
              "      <td>docker</td>\n",
              "      <td>Angular JS</td>\n",
              "      <td>Azure</td>\n",
              "      <td>.js</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Statistician  ... Web Developer\n",
              "0    statistical models  ...    Javascript\n",
              "1  statistical modeling  ...    Typescript\n",
              "2           probability  ...          HTML\n",
              "3   normal distribution  ...         HTML5\n",
              "4  poisson distribution  ...           .js\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2IKqgT88KSr"
      },
      "source": [
        "# create a user defined function to understand the status of the roles\n",
        "# to do this we would use the PhraseMatcher\n",
        "def getRolesStatus(text,ky_roles,st_en):\n",
        "    words={role:None for role in ky_roles}\n",
        "    for role in ky_roles:\n",
        "        words[role] = [st_en(tt) for tt in ky_roles[role].dropna(axis=0)]\n",
        "    \n",
        "    matcher = PhraseMatcher(st_en.vocab)\n",
        "    for role in ky_roles:\n",
        "        matcher.add(role,None,*words[role])\n",
        "    \n",
        "    doc = st_en(text) # Document\n",
        "    d = []  \n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        rule_id = st_en.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
        "        span = doc[start : end]  # get the matched slice of the doc\n",
        "        d.append((rule_id, span.text))      \n",
        "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
        "    \n",
        "    ## convertimg string of keywords to dataframe\n",
        "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
        "    df1 = pd.DataFrame(df.Keywords_List.str.split('(',1).tolist(),columns = ['Subject','Count'])\n",
        "    df1.Subject = [' '.join(x.split(' ')[:-2]) for x in df1.Subject]\n",
        "    df2 = pd.concat([df1['Subject'],df1['Count'].str.replace(')','')], axis =1) \n",
        "    dataf = pd.concat([df2['Subject'], df2['Count']], axis = 1)\n",
        "\n",
        "    return(dataf)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-azzAYpE8gYW"
      },
      "source": [
        "from spacy.matcher import PhraseMatcher\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "ZdRhaPt58PLx",
        "outputId": "b1866d36-c071-4d61-e33b-18d891093ce8"
      },
      "source": [
        "# using this line of code, we are running the UDF to \n",
        "# map any given resume (with its ID) and we get the matching ROLES\n",
        "# rather than only the skills\n",
        "words=getRolesStatus(' '.join(getSkills(data.text.iloc[170],st_en)),ky_roles,st_en)\n",
        "words"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Subject, Count]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLzbJLED_OsF"
      },
      "source": [
        "# **Compiling the Information**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiRXAweS8Tpt"
      },
      "source": [
        "# creating a compilation function : UDF: \n",
        "# wherein we will collect all information for any given text  \n",
        "def compileInformation(text):\n",
        "    info={}\n",
        "    \n",
        "    info['Name']=getName(text,st_en) # name\n",
        "    info['Contact']=getContact(text) # contact details, if any\n",
        "    info['Email']=getEmail(text) # email address, if any\n",
        "    info['Education']=getEducation(text,st_en) # edu. details, if any\n",
        "    info['Skills']=getSkills(text,st_en) # specific skiils\n",
        "    info['Domains']=getRolesStatus(' '.join(getSkills(text,st_en)),ky_roles,st_en).Subject # Roles\n",
        "    return info"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUnXKqqw8qiT",
        "outputId": "2079772a-95f5-4162-aa5c-10964f90149b"
      },
      "source": [
        "# search in all documents/resumes\n",
        "# and list all the properties of them into a single place\n",
        "all_docs=[]\n",
        "for text in tqdm(data.text):\n",
        "    all_docs.append(compileInformation(text))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 228/228 [13:53<00:00,  3.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAkrmOYu8tRw"
      },
      "source": [
        "# dumping the findings as a Pickle file in Binary\n",
        "pickle.dump(all_docs,open('all_docs.pkl','wb'))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc43OcwX8w4P"
      },
      "source": [
        "# Reading it back again as a different variable\n",
        "all_docs=pickle.load(open('all_docs.pkl','rb'))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_J7QWux82FB"
      },
      "source": [
        "# for example: trying to read the domains/Roles from the compiled information\n",
        "# which we have got out of the resumes that we scanned as part of this study\n",
        "all_domains=[]\n",
        "for doc in all_docs:\n",
        "    all_domains.extend(doc['Domains'])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVP3dj0z847H"
      },
      "source": [
        "# save the domains we have found as a series of elements\n",
        "all_domains=pd.Series(all_domains)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "4PkUrnnC87h4",
        "outputId": "aefcde48-78dd-4df3-fbf1-6ecf96e45767"
      },
      "source": [
        "# e.g., we are using PLotly library to display the histograms of the available\n",
        "# roles which have matched from the given set of Resumes. \n",
        "px.bar(x=all_domains.value_counts().index,y=all_domains.value_counts().values)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"01b31aef-afdf-45ff-b54c-edb63da4f0a9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"01b31aef-afdf-45ff-b54c-edb63da4f0a9\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '01b31aef-afdf-45ff-b54c-edb63da4f0a9',\n",
              "                        [{\"alignmentgroup\": \"True\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"\", \"offsetgroup\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"JAVA developer\", \"Web Developer\", \"Data Engineering\", \"Machine Learning Engineer\", \"Cloud Engineer\", \"Deep Learning Engineer\"], \"xaxis\": \"x\", \"y\": [173, 130, 110, 104, 39, 35], \"yaxis\": \"y\"}],\n",
              "                        {\"barmode\": \"relative\", \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('01b31aef-afdf-45ff-b54c-edb63da4f0a9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91ORcmX89pB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}